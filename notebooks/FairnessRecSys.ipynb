{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "PU-DICOY_RZR"
      },
      "source": [
        "# Tutorial on Fairness in Recommender System\n",
        "\n",
        "In this notebook, we become familiar with the Python recommendation toolbox, in the simplest possible way. First, we setup the working environment in GDrive. Then, we go through the experimental pipeline, by:\n",
        "\n",
        "- loading the Movielens 1M dataset;\n",
        "- performing a train-test splitting;\n",
        "- creating a pointwise / pairwise / random / mostpop recommendation object;\n",
        "- training the model (if applicable);\n",
        "- computing the user-item relevance matrix;\n",
        "- calculating some of the recommendation metrics (e.g., NDCG, Item Coverage, Diversity, Novelty).\n",
        "\n",
        "The trained models, together with the partial computation we will save (e.g., user-item relevance matrix or metrics), will be the starting point of the investigation and the treatment covered by the other Jupyter notebooks.\n",
        "\n",
        "**<font color='red'>IMPORTANT</font>**: _Please go the \"Runtime\" option in the top menu, then click on \"Change runtime\" and select \"GPU\"._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tfQL85o__RZT"
      },
      "source": [
        "## Setup the working environment for this notebook\n",
        "\n",
        "- Python 3.6\n",
        "- Package Requirements: matplotlib, numpy, pandas, scikit-learn, scipy, tensorflow-gpu==2.0\n",
        "- Storage requirements: around 1GB"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Ed4yb65_RZU"
      },
      "source": [
        "This step serves to mount GDrive storage within this Jupyter notebook. The command will request us to give access permissions to this notebook, so that we will be able to clone the project repository when we desire. Please follow the prompted instructions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eDPYh1Op_RZV"
      },
      "source": [
        "We will clone the project repository in our My Drive folder. If you wish to change the target folder, please modify the command below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CXY7xlEn_RZV",
        "outputId": "7f5016af-7d5b-4147-895b-e21667400fcd"
      },
      "outputs": [],
      "source": [
        "! git clone https://github.com/rahmanidashti/FairnessRecSysTutorial.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BhKDSJDg_RZV"
      },
      "source": [
        "We will move to the project folder in order to install the required packages."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uOC_UKsa_RZW",
        "outputId": "4efd532d-c167-4975-b467-5cce466d5e15"
      },
      "outputs": [],
      "source": [
        "%cd FairnessRecSysTutorial/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jZfMcJlI_RZW",
        "outputId": "262acd75-a8c9-4ae4-a13c-e766ed3d7bc2"
      },
      "outputs": [],
      "source": [
        "! ls"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8DC4UNB8_RZW",
        "outputId": "bbb9d034-55df-4051-b107-e76198d486eb"
      },
      "outputs": [],
      "source": [
        "# ! pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTyt9Fnb_RZW"
      },
      "source": [
        "We will configure the notebooks directory as our working directory in order to simulate a local notebook execution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cMi811KR_RZW",
        "outputId": "3c21e06d-39b7-4a89-91d7-429a552e5988"
      },
      "outputs": [],
      "source": [
        "%cd ./notebooks"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rrzBEiLN_RZW"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HthhyWgD_RZW"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "sys.path.append(os.path.join('..'))\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qgE1GplW_RZW"
      },
      "outputs": [],
      "source": [
        "from helpers.train_test_splitter import *\n",
        "from models.pointwise import PointWise\n",
        "from models.pairwise import PairWise\n",
        "from models.mostpop import MostPop\n",
        "from models.random import Random\n",
        "from helpers.utils import *"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pj-Aeq8e_RZX"
      },
      "source": [
        "We will define the folders where we will store our pre-computed results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cVmq5Cti_RZX"
      },
      "outputs": [],
      "source": [
        "data_path = '../data/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fcftMXTW_RZX"
      },
      "outputs": [],
      "source": [
        "# !mkdir '../data/outputs'\n",
        "# !mkdir '../data/outputs/splits'\n",
        "!mkdir '../data/outputs/instances'\n",
        "!mkdir '../data/outputs/models'\n",
        "!mkdir '../data/outputs/predictions'\n",
        "!mkdir '../data/outputs/metrics'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hickEay_RZX"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DdEuyJzK_RZX"
      },
      "source": [
        "First, we will load the Movielens 1M dataset, which has been pre-arranged in order to comply with the following structure: user_id, item_id, rating, timestamp, type (label for the item category), and type_id (unique id of the item category). For the sake of tutorial easiness, we assume here that each item is randomly assigned to one of its categories in the original dataset. Our toolbox is flexible enough to integrate any other dataset in csv format that has the same structure of the pre-arranged csv shown below. No further changes are needed to experiment with other datasets.   "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TgFve_XE_RZX"
      },
      "outputs": [],
      "source": [
        "dataset = 'ml1m'\n",
        "user_field = 'user_id'\n",
        "item_field = 'item_id'\n",
        "rating_field = 'rating'\n",
        "time_field = 'timestamp'\n",
        "type_field = 'type_id'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gN_t0TPo_RZX"
      },
      "outputs": [],
      "source": [
        "data = pd.read_csv(os.path.join(data_path, 'datasets/' + dataset + '.csv'), encoding='utf8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "2b891Cgz_RZX",
        "outputId": "ea1b602e-b25f-4b56-e2f8-e557a4d707c2"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SBemd_yP_RZX"
      },
      "source": [
        "During this tutorial, we will simulate a scenario with implicit feedback."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XP5OGqQu_RZX"
      },
      "outputs": [],
      "source": [
        "data[rating_field] = data[rating_field].apply(lambda x: 1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "66jVCKYb_RZX"
      },
      "source": [
        "## Split data in train and test sets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NtSOpwcd_RZX"
      },
      "source": [
        "- **smode**: 'uftime' for fixed timestamp split, 'utime' for time-based split per user, 'urandom' for random split per user\n",
        "- **train_ratio**: percentage of data to be included in the train set\n",
        "- **min_train**: minimum number of train samples for a user to be included  \n",
        "- **min_test**: minimum number of test samples for a user to be included\n",
        "- **min_time**: start timestamp for computing the splitting timestamp (only for uftime)\n",
        "- **max_time**: end timestamp for computing the splitting timestamp (only for uftime)\n",
        "- **step_time**: timestamp step for computing the splitting timestamp (only for uftime)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rJUYXUHV_RZX"
      },
      "outputs": [],
      "source": [
        "smode = 'utime'\n",
        "train_ratio = 0.80\n",
        "min_train_samples = 8\n",
        "min_test_samples = 2\n",
        "min_time = None\n",
        "max_time = None\n",
        "step_time = 1000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "76Op1M9d_RZX"
      },
      "source": [
        "During this tutorial, we will work with a common time-based split per user."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lR1tCQt9_RZX",
        "outputId": "17730ab7-54da-4f84-b1dc-795ecff953ab"
      },
      "outputs": [],
      "source": [
        "if smode == 'uftime':\n",
        "    traintest = fixed_timestamp(data, min_train_samples, min_test_samples, min_time, max_time, step_time, user_field, item_field, time_field, rating_field)\n",
        "elif smode == 'utime':\n",
        "    traintest = user_timestamp(data, train_ratio, min_train_samples+min_test_samples, user_field, item_field, time_field)\n",
        "elif smode == 'urandom':\n",
        "    traintest = user_random(data, train_ratio, min_train_samples+min_test_samples, user_field, item_field)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8eLn8AUH_RZX"
      },
      "source": [
        "Please note that user_ids and item_ids have been scaled so that user_ids is in [0, no_users] and item_ids will be in [0, no_items]. If you wish to link these new ids to the older ones, please refer to the user_id_original and item_id_original columns."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "XsGc-oB5_RZX",
        "outputId": "bb2f0eac-fa92-406d-d923-9000a3d22771"
      },
      "outputs": [],
      "source": [
        "traintest.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s4E-1R1-_RZX"
      },
      "source": [
        "For the sake of replicability and efficiency of this tutorial, we will save the pre-computed train and test sets in ./data/outputs/splits"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6H0vnp2j_RZX"
      },
      "outputs": [],
      "source": [
        "traintest.to_csv(os.path.join(data_path, 'outputs/splits/' + dataset + '_' + smode + '.csv'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LiPHiJ-m_RZX"
      },
      "source": [
        "## Run the model train and test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RM2iv-Hs_RZX"
      },
      "source": [
        "We will create two dataframes, one with train feedback and another with test feedback, from the pre-computed split data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nxVkusKj_RZX"
      },
      "outputs": [],
      "source": [
        "train = traintest[traintest['set']=='train'].copy()\n",
        "test = traintest[traintest['set']=='test'].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BO46rtRD_RZc"
      },
      "outputs": [],
      "source": [
        "users = list(np.unique(traintest[user_field].values))\n",
        "items = list(np.unique(traintest[item_field].values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3gocxil_RZc",
        "outputId": "44cdd54b-1950-45fb-aee4-68f63fdbb1af"
      },
      "outputs": [],
      "source": [
        "len(users), len(items)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pprKdOHZ_RZc"
      },
      "outputs": [],
      "source": [
        "category_per_item = traintest.drop_duplicates(subset=['item_id'], keep='first')[type_field].values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKyq30gy_RZc",
        "outputId": "dcd24965-c972-40a5-dd2f-9c0dca852dd4"
      },
      "outputs": [],
      "source": [
        "len(np.unique(category_per_item))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ImghOdMk_RZc"
      },
      "source": [
        "For the sake of easiness, we will focus on four main recommendation strategies:\n",
        "- Random\n",
        "- MostPop\n",
        "- PointWise\n",
        "- PairWise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u2WUw8ps_RZc"
      },
      "outputs": [],
      "source": [
        "model_types = {'random': Random, 'mostpop': MostPop, 'pointwise': PointWise, 'pairwise': PairWise}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a8X_GvSc_RZc"
      },
      "source": [
        "First, we need to initialize the model. We will see how the process works for a PairWise algorithm. Then, we will consider the other ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zB0oUNHM_RZc",
        "outputId": "bd038bf2-6793-40f9-f937-2e3c3029448f"
      },
      "outputs": [],
      "source": [
        "model_type = 'pairwise'\n",
        "model = PairWise(users, items, train, test, category_per_item, item_field, user_field, rating_field)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fjyPWT18_RZc"
      },
      "source": [
        "We will train the model by feeding the train data we previously prepared, with the following default values.\n",
        "\n",
        "- **no_epochs** (default: 100)\n",
        "- **batches** (default: 1024)\n",
        "- **lr** (default: 0.001)\n",
        "- **no_factors** (default: 10)\n",
        "- **no_negatives** (default: 10)\n",
        "- **val_split** (default: 0.0001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBk1Z-9f_RZc",
        "outputId": "a9f75265-6fbf-4f8f-edc6-304fe80c1a4d"
      },
      "outputs": [],
      "source": [
        "model.train(no_epochs=5) # For the sake of tutorial efficiency, we force to stop after 5 epochs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpfZuFYK_RZc"
      },
      "source": [
        "The architecture of the trained model looks as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qFAnZ86_RZc",
        "outputId": "5072e0c4-7ef1-4c0f-fba8-0cc565ef51f2"
      },
      "outputs": [],
      "source": [
        "model.print()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hqAL9m4D_RZc"
      },
      "source": [
        "## Compute user-item relevance scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zv_zTcgi_RZc"
      },
      "source": [
        "Now, we will use the pre-trained model to predict the user-item relevance scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMtjEfyh_RZc",
        "outputId": "2010f085-7b3d-4bf2-d23e-cd66894f15d3"
      },
      "outputs": [],
      "source": [
        "model.predict()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXSwCUZf_RZc"
      },
      "outputs": [],
      "source": [
        "scores = model.get_predictions()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W07dpJo8_RZc"
      },
      "source": [
        "As we expected, the predicted scores are stored in a matrix of shape np_users x no_items."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DjtKsV9z_RZd",
        "outputId": "81c0926a-61be-45d8-b057-873e68b384dc"
      },
      "outputs": [],
      "source": [
        "scores.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HSHenjOn_RZd"
      },
      "source": [
        "Hence, we can access to the relevance score of the user 120 for the item 320 as follows."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUbGjdXD_RZd",
        "outputId": "e4f85d82-db5a-42c2-f1ea-5ee43829284a"
      },
      "outputs": [],
      "source": [
        "user_id, item_id = 120, 320\n",
        "scores[user_id, item_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on2DFwVk_RZd"
      },
      "source": [
        "For the sake of convenience, we will save the predicted scores."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4w-hEOkh_RZd"
      },
      "outputs": [],
      "source": [
        "save_obj(scores, os.path.join(data_path, 'outputs/predictions/' + dataset + '_' + smode + '_' + model_type + '_scores.pkl'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jya3oZoO_RZd"
      },
      "source": [
        "## Calculate metrics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2_w4lkqn_RZd"
      },
      "source": [
        "In this step, we leverage the predicted scores in order to compute a set of common recommendation metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "thddo-E9_RZd"
      },
      "outputs": [],
      "source": [
        "cutoffs = np.array([5, 10, 20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RWiaO43y_RZd"
      },
      "outputs": [],
      "source": [
        "item_group = load_obj(os.path.join(data_path, 'datasets', 'ml1m-item-group'))\n",
        "# we discuss this point in detail in the third notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbbHTWdf_RZd",
        "outputId": "70eff512-9078-4e44-9304-775032dc8621"
      },
      "outputs": [],
      "source": [
        "model.test(item_group=item_group, cutoffs=cutoffs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nmSqSCqX_RZd"
      },
      "source": [
        "The method has pre-computed a set of metrics and saved the corresponding values in a Python dictionary, as detailed below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "70C5qdgK_RZd"
      },
      "outputs": [],
      "source": [
        "metrics = model.get_metrics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L_Yk3txl_RZd",
        "outputId": "467e3551-67e7-4679-f942-a1f36a55bddb"
      },
      "outputs": [],
      "source": [
        "metrics.keys()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xF4T99MH_RZd"
      },
      "source": [
        "The values for each metrics have been computed and store for each cutoff."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oiJMBwb0_RZd",
        "outputId": "d0661704-e6e7-4751-c0f6-1ae93942b658"
      },
      "outputs": [],
      "source": [
        "for name, values in metrics.items():\n",
        "    print(values.shape, name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04DvDsOF_RZd"
      },
      "source": [
        "For instance, we can access to the NDCG score for the user 120 at cutoff 10, with the following commands."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "709OtKu8_RZd",
        "outputId": "36f66f3b-1e5f-48f0-ee02-9219a3a52d62"
      },
      "outputs": [],
      "source": [
        "user_id, cutoff_index = 1324, int(np.where(cutoffs == 10)[0])\n",
        "metrics['ndcg'][cutoff_index, user_id]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPPMYJQC_RZd"
      },
      "source": [
        "For the sake of convenience, we will save the compted metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zwiDIWNX_RZd"
      },
      "outputs": [],
      "source": [
        "save_obj(metrics, os.path.join(data_path, 'outputs/metrics/' + dataset + '_' + smode + '_' + model_type + '_metrics.pkl'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "USBv7_dl_RZd"
      },
      "source": [
        "We can also see the aggregated values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWocgwSg_RZd",
        "outputId": "76729a40-02c4-44c2-c885-a5e4514bb8b2"
      },
      "outputs": [],
      "source": [
        "model.show_metrics(index_k=int(np.where(cutoffs == 10)[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-MDMi6B_RZd"
      },
      "source": [
        "## Repeat the experimental pipeline for Random and MostPop (optionally for PointWise)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HMfiCVwM_RZe"
      },
      "source": [
        "We will define a utility function to perform ll the above operations jointly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_rfgdFKP_RZe"
      },
      "outputs": [],
      "source": [
        "def run_model(model_type, no_epochs=None):\n",
        "    print('Running model', model_type)\n",
        "    model = model_types[model_type](users, items, train, test, category_per_item, item_field, user_field, rating_field)\n",
        "    model.train(no_epochs=no_epochs) if no_epochs else model.train()\n",
        "    model.predict()\n",
        "    scores = model.get_predictions()\n",
        "    save_obj(scores, os.path.join(data_path, 'outputs/predictions/' + dataset + '_' + smode + '_' + model_type + '_scores.pkl'))\n",
        "    model.test(item_group=item_group, cutoffs=cutoffs)\n",
        "    metrics = model.get_metrics()\n",
        "    save_obj(metrics, os.path.join(data_path, 'outputs/metrics/' + dataset + '_' + smode + '_' + model_type + '_metrics.pkl'))\n",
        "    print()\n",
        "    model.show_metrics(index_k=int(np.where(cutoffs == 10)[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NCx1O-Mv_RZe",
        "outputId": "47fc8705-40e2-4d6d-f289-042f09aa25d1"
      },
      "outputs": [],
      "source": [
        "run_model('random')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pnDAY2VY_RZe",
        "outputId": "2a270e5c-1930-4bc0-94f8-58fcde9bcad2"
      },
      "outputs": [],
      "source": [
        "run_model('mostpop')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8LupZba_RZe"
      },
      "source": [
        "## How to extend the toolbox\n",
        "\n",
        "- New splitter: take a look at the helpers/train_test_splitter.py file and how the existing generators have been defined.\n",
        "- New train instances creator: similarly, take a look at the helpers/instances_creator.py file and how the existing generators have been defined.\n",
        "- New model: a new subclass of the Model class defined in models/model.py should be defined, implementing a 'train' and a 'predict' method.\n",
        "- New metrics: both the 'test' and 'show_metrics' methods of models/model.py should be extended with the computation needed by the new metric.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_jMKCMj_RZe"
      },
      "outputs": [],
      "source": [
        "data =  pd.read_csv('../data/outputs/splits/' + dataset + '_' + smode + '.csv', encoding='utf8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HxhKd7cnxr3k"
      },
      "outputs": [],
      "source": [
        "item_pop = data.groupby([item_field]).count().sort_values(user_field, ascending=False)[user_field]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PsvP6rccxuaj",
        "outputId": "c335d726-c3d7-4878-ce3f-76fba4075000"
      },
      "outputs": [],
      "source": [
        "item_pop.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HHuieB1bx0_B"
      },
      "source": [
        "For the sake of easiness, we conduct our study focusing on two sets of items: most popular items and less popular items. To this end, we will consider the most popular 800 items in the first set, while the remaining items are included in the second set. Several ways to split items in these two sets arefound in literature (e.g., most popular items that receive the 80% of the overall ratings).    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OpiYHPNBxv_K"
      },
      "outputs": [],
      "source": [
        "head_tail_split = 808\n",
        "head_tail_items = np.array(item_pop[:head_tail_split].index)\n",
        "long_tail_items = np.array(item_pop[head_tail_split:].index)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IA5NPfwpx3FX",
        "outputId": "4ab62e29-36f0-4036-9b8b-78eab323463e"
      },
      "outputs": [],
      "source": [
        "print('Head Tail', compute_gini(item_pop[:head_tail_split]))\n",
        "print('Long Tail', compute_gini(item_pop[head_tail_split:]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "qMo5-23Mx4YO",
        "outputId": "514dfadb-e427-47bf-a6aa-94ccc6c3da17"
      },
      "outputs": [],
      "source": [
        "plt.rcParams.update({'font.size': 8})\n",
        "plt.figure(figsize=(6, 3.5))\n",
        "\n",
        "plt.title(r'Item popularity')\n",
        "plt.xlabel('Items ranked by popularity')\n",
        "plt.ylabel('Number of ratings in the dataset')\n",
        "plt.plot(range(head_tail_split), item_pop.values[:head_tail_split], alpha=0.7, label=r'Head tail')\n",
        "plt.plot(range(head_tail_split, len(item_pop.index)), item_pop.values[head_tail_split:], label=r'Long tail')\n",
        "plt.axhline(y=item_pop.values[head_tail_split], linestyle='--', lw=1, c='grey')\n",
        "plt.axvline(x=head_tail_split, linestyle='--', lw=1, c='grey')\n",
        "plt.xlim([-25, len(item_pop.index)])\n",
        "plt.ylim([-25, item_pop.values[0]])\n",
        "plt.legend()\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LDE7KXoEyGZT"
      },
      "source": [
        "Please note how the curve is skewed towards items with only few ratings. In our case, most popular items are those receving more than 450 ratings. In the rest of this study, we will investigate how recommendation algorithms treat items belonging to these sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-az2ks3yKii"
      },
      "source": [
        "## Data analysis: popularity of the recommended items"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9S7IVIoSyIlK"
      },
      "source": [
        "We will use the same cutoffs we have configured in the first notebook.\n",
        "\n",
        "**IMPORTANT BOOKMARK** Please bookmark this point."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jtMR0voUx6Lm"
      },
      "outputs": [],
      "source": [
        "cutoffs = np.array([5, 10, 20])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GzTiykliyM0O"
      },
      "outputs": [],
      "source": [
        "model_types = ['utime_pairwise', 'utime_random', 'utime_mostpop']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAyr7qJgyQBu"
      },
      "source": [
        "To speed up, we will load the metrics pre-computed in the first notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_fxK2IZ7yOLw"
      },
      "outputs": [],
      "source": [
        "metrics = {}\n",
        "for model_type in model_types:\n",
        "    metrics[model_type] = load_obj(os.path.join(data_path, 'outputs/metrics/' + dataset + '_' + model_type + '_metrics.pkl'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IcpIy7gczX1a"
      },
      "source": [
        "First, we will compare the considered algorithms based on their recommendation effectiveness: precision, recall, and NDCG."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "T3Klc14GyR6q",
        "outputId": "5d755948-ac06-44a0-c21b-bf509ffa159b"
      },
      "outputs": [],
      "source": [
        "plt.rcParams.update({'font.size': 16.5})\n",
        "plt.figure(figsize=(30, 7.5))\n",
        "\n",
        "plt.subplot(131)\n",
        "plt.title(r'Precision')\n",
        "plt.xlabel('Cutoff Value')\n",
        "plt.ylabel('Precision')\n",
        "for model_type in model_types:\n",
        "    plt.plot(cutoffs, [np.mean(metrics[model_type]['precision'][k,:]) for k in range(len(cutoffs))], label=model_type)\n",
        "plt.xticks(cutoffs)\n",
        "plt.legend()\n",
        "plt.grid(axis='y')\n",
        "\n",
        "plt.subplot(132)\n",
        "plt.title(r'Recall')\n",
        "plt.xlabel('Cutoff Value')\n",
        "plt.ylabel('Recall')\n",
        "for model_type in model_types:\n",
        "    plt.plot(cutoffs, [np.mean(metrics[model_type]['recall'][k,:]) for k in range(len(cutoffs))], label=model_type)\n",
        "plt.xticks(cutoffs)\n",
        "plt.legend()\n",
        "plt.grid(axis='y')\n",
        "\n",
        "plt.subplot(133)\n",
        "plt.title(r'NDCG')\n",
        "plt.xlabel('Cutoff Value')\n",
        "plt.ylabel('NDCG')\n",
        "for model_type in model_types:\n",
        "    plt.plot(cutoffs, [np.mean(metrics[model_type]['ndcg'][k,:]) for k in range(len(cutoffs))], label=model_type)\n",
        "plt.xticks(cutoffs)\n",
        "plt.legend()\n",
        "plt.grid(axis='y')\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M10OQ6F0zb0n"
      },
      "source": [
        "Please note that pairwise and mostpop algorithms have a really similar behavior for all the considered metrics. Nove, we move our attention to the popularity of the recommended items and the coverage of the items we marked as \"less popular\".  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "id": "7i-yeqWizZSz",
        "outputId": "4208d456-d01c-43f3-e125-257d32e66375"
      },
      "outputs": [],
      "source": [
        "plt.rcParams.update({'font.size': 16.5})\n",
        "plt.figure(figsize=(30, 7.5))\n",
        "\n",
        "plt.subplot(131)\n",
        "plt.title(r'Average Popularity of Items')\n",
        "plt.xlabel('Cutoff Value')\n",
        "plt.ylabel('APT')\n",
        "for model_type in model_types:\n",
        "    plt.plot(cutoffs, [np.mean(metrics[model_type]['mean_popularity'][k,:]) for k in range(len(cutoffs))], label=model_type)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(132)\n",
        "plt.title(r'Average Percentage of Less Popular Items')\n",
        "plt.xlabel('Cutoff Value')\n",
        "plt.ylabel('APLT')\n",
        "for model_type in model_types:\n",
        "    plt.plot(cutoffs, [np.sum(metrics[model_type]['item_coverage'][k,long_tail_items]) / np.sum(metrics[model_type]['item_coverage'][k,:]) for k in range(len(cutoffs))], label=model_type)\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(133)\n",
        "plt.title(r'Item Coverage')\n",
        "plt.xlabel('Cutoff Value')\n",
        "plt.ylabel('Item Coverage')\n",
        "for i, model_type in enumerate(model_types):\n",
        "    plt.plot(cutoffs, [len([1 for m in metrics[model_type]['item_coverage'][k,head_tail_items] if m > 0]) / len(head_tail_items) for k in range(len(cutoffs))], color='C'+str(i), linestyle='-', label='pop head of ' + model_type)\n",
        "    plt.plot(cutoffs, [len([1 for m in metrics[model_type]['item_coverage'][k,long_tail_items] if m > 0]) / len(long_tail_items) for k in range(len(cutoffs))], color='C'+str(i), linestyle=':', label='pop tail of ' + model_type)\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NQ1DnKPuzhTM"
      },
      "source": [
        "These figures show us that the average popularity of items recommended by the pairwise algorithm is really high and not so far from the one of items recommended by mostpop. This observation is also confirmed by the coverage of items from the \"less popular\" set. For small cutoffs, pairwise and mostpop recommened only a tiny fraction of the less popular items."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fKbiKujPzjP1"
      },
      "source": [
        "## Sample treatment to promote less popular items: post-processing\n",
        "\n",
        "In this part, we will show how to setup and perform a post-processing mitigation approach. We show a didactic version of the xQuad algorithm adaptation proposed by Adbollahpouri et al. (2018). A model able to perform a re-ranking of the items has the same structure of the models we considered so far. Therefore, we first need to prepare all the data needed to initialize a model, as done in the first notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KJ2QwTl6zeQb"
      },
      "outputs": [],
      "source": [
        "traintest = pd.read_csv('../data/outputs/splits/' + dataset + '_' + smode + '.csv', encoding='utf8')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tf8dQ-DmzliR"
      },
      "outputs": [],
      "source": [
        "train = traintest[traintest['set']=='train'].copy()\n",
        "test = traintest[traintest['set']=='test'].copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nvj5P3GSznLK"
      },
      "outputs": [],
      "source": [
        "users = list(np.unique(traintest[user_field].values))\n",
        "items = list(np.unique(traintest[item_field].values))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2pUsphezoQQ"
      },
      "outputs": [],
      "source": [
        "items_metadata = traintest.drop_duplicates(subset=['item_id'], keep='first')\n",
        "category_per_item = items_metadata[type_field].values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QIEhcGYCzr5B"
      },
      "source": [
        "Now, we are ready to import and usethe re-ranking model mentioned above."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4R_y9WihzpfN",
        "outputId": "fa7ba7d7-2c32-4d9c-e14d-7949410a0a17"
      },
      "outputs": [],
      "source": [
        "from models.ranker_xquad import RankerXQuad\n",
        "model = RankerXQuad(users, items, train, test, category_per_item, item_field, user_field, rating_field)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qAZUYFfBztqb"
      },
      "outputs": [],
      "source": [
        "original_model_type = 'utime_pairwise' # This string identifies the recommendation algorithm where the re-ranking is applied\n",
        "reranked_model_type = original_model_type + '_' + 'xquad' # This string is an identifier for models results in data/outputs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vNT6BaPjzx_k"
      },
      "source": [
        "We initialize the model predictions with those of the original recommendation model, precomputed in the first notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3ii1izH-zvzu"
      },
      "outputs": [],
      "source": [
        "predictions = load_obj(os.path.join(data_path,'outputs/predictions/' + dataset + '_' + original_model_type + '_scores.pkl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FG0sbxQvz0FD"
      },
      "outputs": [],
      "source": [
        "model.set_predictions(predictions)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EepIdJVYz5YT"
      },
      "source": [
        "Now, we can run the re-ranking process and save the positional relevance of items for users after re-ranking. Note, you can skip the following cells load directly our pre-computed re-ranking predictions."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JFzevNFYIIGn"
      },
      "outputs": [],
      "source": [
        "model.rerank(type='smooth', lmbda=0.4, k=10, rmax=100, head_tail_split=head_tail_split)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sVYOcxScIJEm"
      },
      "outputs": [],
      "source": [
        "predictions = model.get_predictions()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOlrqE6NIMMD"
      },
      "outputs": [],
      "source": [
        "save_obj(predictions, os.path.join(data_path, 'outputs/predictions/' + dataset + '_' + reranked_model_type + '_scores.pkl'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lVDF5Az7IPrA"
      },
      "source": [
        "Finally, we compute and show the metrics for the recommender systems obtained after re-ranking."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y7ywSqhfITDH"
      },
      "outputs": [],
      "source": [
        "model.test(cutoffs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vP0ON2acITeA"
      },
      "outputs": [],
      "source": [
        "metrics = model.get_metrics()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3BXRJOFiIVmq"
      },
      "outputs": [],
      "source": [
        "save_obj(metrics, os.path.join(data_path, 'outputs/metrics/' + dataset + '_' + reranked_model_type + '_metrics.h5'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Pw_9Ij10DDP"
      },
      "source": [
        "**To speed up**\n",
        "\n",
        "This re-ranking takes several minutes. For this tutorial, please feel free to stop and load directly our pre-computed re-ranking predictions (2 MB).  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3HyBZnWz0Fma"
      },
      "outputs": [],
      "source": [
        "model.set_metrics(load_obj('../data/outputs/metrics/ml1m_utime_pairwise_xquad_metrics.pkl'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DWtwT4ie0l8Z",
        "outputId": "f3924913-2d7c-49a7-be84-edb93ab63ee8"
      },
      "outputs": [],
      "source": [
        "model.show_metrics(index_k=int(np.where(cutoffs == 10)[0]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lMDUmIsY0p4j"
      },
      "source": [
        "Finally, we have obtained the metrics resulting from the considered strategy. Now, we come back to the **IMPORTANT BOOKMARK** mention ed above, using cutoffs = np.array([5, 10]) and adding 'utime_pairwise_xquad' to the model_types list. Then, we can rerun all the cells for plotting in order to compare the results obtained with these strategy against the ones of the baseline recommendation algorithms."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
